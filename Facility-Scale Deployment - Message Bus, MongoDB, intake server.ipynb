{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facility-Scale Deployment: Message Bus, MongoDB, intake server\n",
    "\n",
    "## Scenario\n",
    "\n",
    "This is an approximation of a deployment \"at scale,\" such as at a large experimental facility.\n",
    "\n",
    "Here, bluesky's **RunEngine** is configured to dispatch the documents generated during data acquisition to a (very lightweight) **message bus**. A **consumer** is listening to the message bus and inserting Documents into a **MongoDB** instance, which stores the data at rest.\n",
    "\n",
    "RunEngine -> 0MQ Publisher -> 0MQ Proxy -> 0MQ Subscriber -> MongoDB\n",
    "\n",
    "An **intake server** has access to the MongoDB and to any externally-stored files written directly to disk by large detectors. It serves all of this to users over HTTP.\n",
    "\n",
    "In this demo deployment, everything happens to be on the same machine, but it need not be. The user will never directly connect to the MongoDB or directly access the filesystem where data files are stored.\n",
    "\n",
    "## First: Check that services are running\n",
    "\n",
    "The lightweight message bus (``bluesky-0MQ-proxy``), the consumer (``consumer.py``), a user-space MongoDB daemon (``run-mongobox.py``), and the ``intake-server`` should already been automatically started by supervisor. Confirm that they are running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!supervisorctl -c supervisor/supervisord.conf status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from bluesky.utils import install_nb_kicker\n",
    "install_nb_kicker()\n",
    "\n",
    "from bluesky import RunEngine\n",
    "from bluesky.plans import scan\n",
    "from bluesky.preprocessors import SupplementalData\n",
    "from ophyd.sim import motor, det\n",
    "from bluesky.callbacks.zmq import Publisher\n",
    "from bluesky.callbacks.mpl_plotting import LivePlot\n",
    "\n",
    "RE = RunEngine({})  # executor for experiment procedures\n",
    "publish_to_message_bus = Publisher('localhost:5577')\n",
    "RE.subscribe(publish_to_message_bus);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire Data Using Bluesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(scan([det], motor, -1, 1, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documents generated by the scan have to published in a streaming fashion and ultimately encoded as MongoDB Documents. The uid(s) returned by ``RE`` uniquely identify the data.\n",
    "\n",
    "To get some live feedback, we can additional dispatch the documents into a live-streaming plot. Additionally, we'll capture that unique ID in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid, = RE(scan([det], motor, -1, 1, 20), LivePlot('det', 'motor'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access saved data using intake\n",
    "\n",
    "### Connect to the intake server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intake import Catalog\n",
    "import intake_bluesky.mongo_layout1\n",
    "\n",
    "catalog = Catalog('intake://localhost:5000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the 'run' of interest\n",
    "\n",
    "In this case, we have its globally unique ID, so we can just look it up directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = catalog['xyz'][uid]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For interactive analysis, get a PyData/Scipy structure (e.g. xarray)\n",
    "\n",
    "Each Event Stream (logical table) in the acquired data is a subcatalog. The number and name of the streams depends on the application, but ``'primary'`` is commonly the one of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.primary.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To rerun bluesky's streaming/viz tooling on saved data, get the original Documents\n",
    "\n",
    "This reproduces the same stream of Documents that was originally emitted by ``RE``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_plot = LivePlot('det', 'motor')\n",
    "for name, doc in catalog['xyz'][uid].read_canonical():\n",
    "    live_plot(name, doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
